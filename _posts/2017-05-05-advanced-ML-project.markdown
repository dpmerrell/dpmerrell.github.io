---
layout: post
title:  "CS 761 project: spectral methods for latent variable models"
date:   2017-05-05 14:00:00 -0500
category: coursework 
tags: [machine learning, bayesian, tensor] 
---

One of my courses this past semester was [CS761](http://pages.cs.wisc.edu/~jerryzhu/cs761.html), 
"Advanced Machine Learning".
The idea of the course was to present some of the mathematical and statistical
theory underlying machine learning. It was taught by 
Dr. [Xiaojin (Jerry) Zhu](http://pages.cs.wisc.edu/~jerryzhu/).

One of the things we had to do was a course project. Since CS761 was a 
theory course, the project needed to be of a theoretical nature. Rather than
merely *applying* machine learning to some problem, we were expected to peruse the
theoretical machine learning literature and try making some contribution to the
research.

Three weeks before the semester ended---after much procrastination---I 
finally buckled down and got to work. I teamed up with 
[Parikshit Sharma](https://www.cs.wisc.edu/people/parikshit); we had 
both, independently, stumbled on the topic of *spectral methods* for 
latent variable models, and decided to pursue possibilities in that area.

The main idea is that we can sometimes learn the parameters of
a Bayesian network by computing a *spectral decomposition*
of certain *empirical moment* tensors obtained from the data.
Parikshit and I tried to do this for new kinds of Bayesian networks.
We were not ultimately successful; however, the project was still
an instructive exercise, and I feel like I got pretty familiar with
the subject matter. 

I felt kind of proud of our work. And it got a decent score. So I've decided to post it here.

[Here's a link to our completed project.]({{site.url}}/assets/coursework/merrell-sharma-cs761-project-2017.pdf)

\\( \blacksquare\\)  


