---
layout: post
title:  "Error, bias, variance, and the human condition"
date:   2019-11-17 00:00:00 -0500
category: personal 
tags: [psychology, philosophy] 
---


![irreducible error, bias, and variance]({{ site.baseurl }}/assets/images/error-bias-variance.png)


## **Error = Irreducible Error + Bias + Variance**

A fundamentally important concept from machine learning and statistics is the _decomposition of prediction error_.

Very informally: the total "wrongness" of a predictor is the sum of (at least) three _subtypes_ of "wrongness":

1. **Irreducible error.** Some prediction tasks are intrinsically more difficult than others. If a system is complex, chaotic, or only partially observed, then we will have a hard time making accurate predictions about it. But if a system is simple, linear, or fully observed, then we will have much less difficulty making accurate predictions. This irreducible error is a property of the _prediction task itself_&mdash;any prediction technique we might choose will be subject to it.
2. **Bias.** When we choose a model for a prediction task, we impose a set of corresponding assumptions&mdash;informally, we can call these assumptions _biases_. For example: if we choose to use linear regression, then we are in effect assuming that our predicted value \\(y\\) is generated by a linear combination of input variables \\(X\\): that is, \\(y = Xw + b \\). If this assumption is false (and it almost always is), then  _any_ linear regression that we choose will make errors when we use it for prediction. This bias represents the predictor's _systemic mistakes_.
3. **Variance.** Our predictor may have an element of randomness to it; it may make different predictions for the same inputs if we run it multiple times. This isn't usually a good design for a predictor (unless it operates in an adversarial setting where some unpredictability is useful), so we usually implement fully deterministic predictors. However, even if our predictor is totally deterministic, it will be subject to the _randomness in the dataset we fit it to_. That is, if we replaced our dataset with a new dataset and re-fit the predictor, then it might make radically different predictions. We use the term _variance_ to refer to the predictor's randomness. It represents the predictor's _unreliability_. 

Some interesting phenomena that data scientists observe in practice: 

* There is usually a _tradeoff_ between a predictor's bias and variance.
  That is: predictors with high bias usually have low variance; and 
  predictors with high variance usually have low bias.
* The parameter which controls this tradeoff is the _complexity_ of the predictor. I.e., simple predictors tend to have high bias/low variance, while complicated predictors usually have low bias/high variance.
* The optimal amount of predictor complexity is usually proportional to the amount of data available for training that predictor. That is: we are better off using simple models when we have little data; and complicated models when we have a lot of data.

## **Human Fallibility**

Most of us go through life with some concept of human fallibility echoing in our heads: 

_I'm not perfect_&mdash;_I'm only human._ 

or 

_Humans make mistakes._

This is with good reason. 
History is replete with examples of poor judgment.
And when we rely on humans&mdash;whether it be ourselves or someone else&mdash;we are often met with disappointment.

What happens when we view _human_ fallibility through the lens of bias, variance, and irreducible error?

### **Irreducible Error**

Many human mistakes result from fundamental difficulties: 
the world is complex and mostly unobserved. 
There are unknown unknowns. 
We are subjected to certain unavoidable challenges as we navigate this uncertain environment.

One could invoke religious language, and call this kind of error _original sin_.

A classic concept from Stoic philosophy: we can divide our circumstances into those _within_ our control, and those _outside_ of our control.

Irreducible error stems from the circumstances that are out of our control.

Stoicism makes the useful suggestion that we focus on the things within our control, and not attach emotional significance to the things outside our control.

My pessimism inclines me to think irreducible error is large.

My optimism inclines me to think that humans do pretty well in spite of it, all things considered.

### **High Bias**

A lack of subtlety or nuance. Black and white thinking.

This is&mdash;perhaps to a small degree&mdash;within our control.

Some worthwhile questions to ask ourselves, in order to understand or address our personal biases:

* _Should I trust my reflexive reaction in this situation? Or is deeper deliberation warranted?_
* _What incorrect assumptions am I taking for granted?_
* _What nuance am I failing to see in the present situation?_
* _What bullshit stories am I telling myself?_
* _Who can I disagree with in a constructive manner, to help correct my own bias?_

### **High Variance**

I wager that any human who thinks much about their own behavior will eventually reach the same, puzzling conclusion: _I fail to do the things I know I should be doing_&mdash;_even when I claim that I **want** to do them._ 

An undisciplined mind.
Impulsiveness.

What Aristotle called "incontinence".

Freudian view: the human mind is composed of conflicting subconscious wills.
They may be poorly integrated&mdash;behavior will depend on which of these wills happens to be dominant at a given time. 

Some worthwhile questions to ask, in order to examine our own "variances":

* _What values or ideals do I hold, consciously or unconsciously?_
* _Is my behavior consistent with my own values?_ 
* _What impulses drive my behavior? Can I improve my control over them?_
* _What is the smallest, simplest, easiest action I can take to behave more consistently with my values?_



\\( \blacksquare\\)  

